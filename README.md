# TAMERS
Transformer Audio-Text Multimodal Emotion Recognizer for Speech - a novel approach to Speech Emotion Recognition

# Citations
```
@inproceedings{poria2018meld,
  title     = {MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversation},
  author    = {Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Mihalcea, Rada and Cambria, Erik},
  year      = {2018}
}
```

```
@article{chen2018emotionlines,
  title     = {EmotionLines: An Emotion Corpus of Multi-Party Conversations},
  author    = {Chen, Szu-Yu and Hsu, Chao-Chun and Kuo, Chao-Chun and Ku, Lun-Wei},
  journal   = {arXiv preprint arXiv:1802.08379},
  year      = {2018}
}
```

```
@article{radford2019language,
  title     = {Language Models are Unsupervised Multitask Learners},
  author    = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal   = {OpenAI Blog},
  volume    = {1},
  number    = {8},
  year      = {2019},
  url       = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}
```

```
@inproceedings{gong2021ast,
  title     = {AST: Audio Spectrogram Transformer},
  author    = {Gong, Yuan and Chung, Yu-An and Glass, James},
  booktitle = {Interspeech},
  year      = {2021}
}
```
